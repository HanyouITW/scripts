#!/bin/bash

#This tells the scheduler what account to use.  Do not change.
#PBS -A junzli_flux
#This is the job name.  Feel free to change this at will to whatever you need.
#PBS -N 2018.08.28.picard_markduplicates.rat_genome_01.s-BN-N_HL53WCCXX_L2.clean.fq.gz.sam.bam.pbs
#This denotes the queue that the job should be run in.  Do not change if you want to use the flux dedicated nodes
#PBS -q flux
#The next two denotes the email address to send jobs to, and under what conditions to send that email.
#PBS -M hanyou@umich.edu
#This line says (a) send email if the job fails, (b) when the job starts, and (e) when the job ends.
#PBS -m abe
#This line combine e file into o file.
#PBS -j oe
#This line sends all environment variables on the login node.
#PBS -V
#This denotes the number of nodes and processors that the job should be run on. The max for ppn is currently 12.
#Walltime is denoted by hh:mm:ss, and hours can be no more than 376 (or 28 days).
#PBS -l nodes=1:ppn=1,pmem=20gb,walltime=200:00:00
#PBS -l qos=flux

mkdir -p /scratch/junzli_flux/hanyou/data2/picard_markduplicates/rat_genome_01
cd /scratch/junzli_flux/hanyou/data2/picard_markduplicates/rat_genome_01
java -Xmx18g -jar $PICARD_JARS/MarkDuplicates.jar INPUT=/scratch/junzli_flux/hanyou/data2/picard_sortsam/rat_genome_01/s-BN-N_HL53WCCXX_L2.clean.fq.gz.sam.bam OUTPUT=/scratch/junzli_flux/hanyou/data2/picard_markduplicates/rat_genome_01/s-BN-N_HL53WCCXX_L2.clean.fq.gz.sam.bam.bam METRICS_FILE=/scratch/junzli_flux/hanyou/data2/picard_markduplicates/rat_genome_01/s-BN-N_HL53WCCXX_L2.clean.fq.gz.sam.bam.txt ASSUME_SORTED=true OPTICAL_DUPLICATE_PIXEL_DISTANCE=2500 TMP_DIR=/scratch/junzli_flux/hanyou/tmp REMOVE_DUPLICATES=false VALIDATION_STRINGENCY=SILENT CREATE_INDEX=true

